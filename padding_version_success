
import torch
import torch.nn as nn
import torch.nn.functional as F

import numpy as np

import random
class CustomCNN(nn.Module):
    def __init__(self):
        # NOTE: you can freely add hyperparameters argument
        super(CustomCNN, self).__init__()
        ##############################################################################
        #                          IMPLEMENT YOUR CODE                               #
        ##############################################################################
        # Problem1-1: define cnn model        

        self.conv_layer = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size = 7, padding = 3, stride = 1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
        )
        self.res1_layer = nn.Sequential(
            nn.Conv2d(32,64,kernel_size = 3, padding = 1, stride = 1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(64,64,kernel_size = 3, padding = 1, stride = 1),
            nn.BatchNorm2d(64),
        )
        self.res2_layer = nn.Sequential(
            nn.Conv2d(64,128,kernel_size = 3, padding = 1, stride = 2),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(128,128,kernel_size = 3, padding = 1, stride = 1),
            nn.BatchNorm2d(128),
        )
        self.res3_layer = nn.Sequential(
            nn.Conv2d(128,128,kernel_size = 3, padding = 1, stride = 2),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(128,128,kernel_size = 3, padding = 1, stride = 1),
            nn.BatchNorm2d(128),
        )
        self.skip1 = nn.Sequential(
            nn.Conv2d(32,64,kernel_size = 1,bias = False),
            nn.BatchNorm2d(64),
        )
        self.skip2 = nn.Sequential(
            nn.Conv2d(64,128,kernel_size = 1, stride = 2,bias = False),
            nn.BatchNorm2d(128),
        )
        self.skip3 = nn.Sequential(
            nn.Conv2d(128,128,kernel_size = 1, stride = 2,bias = False),
            nn.BatchNorm2d(128),
        )
        self.Avgpool = nn.AdaptiveAvgPool2d((2,2))
        self.FC = nn.Sequential(
            nn.Linear(512,64),
        )
        self.ReLU = nn.Sequential(
            nn.ReLU(),
        )
        ##############################################################################
        #                          END OF YOUR CODE                                  #
        ##############################################################################

    def forward(self, inputs):
        """
        For reference (shape example)
        inputs: Batch size X (Sequence_length, Channel=1, Height, Width)
        outputs: (Sequence_length X Batch_size, Hidden_dim)
        """
        ##############################################################################
        #                          IMPLEMENT YOUR CODE                               #
        ##############################################################################
        # Problem1-2: code CNN forward path        
        outputs = self.conv_layer(inputs)
        #print("1st output: {} ".format(outputs.shape))
        
        outputs = self.skip1(outputs) + self.res1_layer(outputs)
        outputs = self.ReLU(outputs)
        outputs = self.skip2(outputs) + self.res2_layer(outputs)
        outputs = self.ReLU(outputs)
        outputs = self.skip3(outputs) + self.res3_layer(outputs)
        outputs = self.ReLU(outputs)
        
        outputs = self.Avgpool(outputs)
        
        #print("Avg pooled output: {} ".format(outputs.shape))
        #print(outputs.shape)
        
        outputs = outputs.view(outputs.shape[0],-1)
        outputs = self.FC(outputs)
        ##############################################################################
        #                          END OF YOUR CODE                                  #
        ##############################################################################
        return outputs

class LSTM(nn.Module):
    def __init__(self, input_dim, hidden_size, vocab_size, num_layers=1, dropout=0.0):
        super(LSTM, self).__init__()

        # define the properties
        self.input_dim = input_dim
        self.hidden_size = hidden_size
        self.vocab_size = vocab_size
        
        ##############################################################################
        #                          IMPLEMENT YOUR CODE                               #
        ##############################################################################
        # Problem2-1: Define lstm and input, output projection layer to fit dimension
        # output fully connected layer to project to the size of the class
        
        # you can either use torch LSTM or manually define it
        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)
        self.fc_in = nn.Linear(input_dim, hidden_size)
        self.fc_out = nn.Linear(hidden_size, vocab_size)
        
        ##############################################################################
        #                          END OF YOUR CODE                                  #
        ##############################################################################

    def forward(self, feature, h, c):
        """
        For reference (shape example)
        feature: (Sequence_length, Batch_size, Input_dim)
        """
        ##############################################################################
        #                          IMPLEMENT YOUR CODE                               #
        ##############################################################################
        # Problem2-2: Design LSTM model for letter sorting
        # NOTE: sequence length of feature can be various    
        #print("feature.shape : ", feature.shape)    #seqlen, 256, 64





        embed = self.fc_in(feature) #batch_size, max_seqlen, hidden_size
        #if seq_lengths is None:
        output, (h_next , c_next) = self.lstm(embed,(h,c))

        #else:
        #  packed = torch.nn.utils.rnn.pack_padded_sequence(embed, seq_lengths.cpu().numpy(), batch_first=True)
        #  #batch_size, 
        #  output, (h_next , c_next) = self.lstm(packed,(h,c))
        #  output, _ = torch.nn.utils.rnn.pad_packed_sequence(output)

        #output.shape = batch_size, max_seqlen, hidden_size
        output = self.fc_out(output)
        ##############################################################################
        #                          END OF YOUR CODE                                  #
        ##############################################################################
        
        # (sequence_lenth, batch, num_classes), (num_rnn_layers, batch, hidden_dim), (num_rnn_layers, batch, hidden_dim)
        return output, h_next, c_next  


class ConvLSTM(nn.Module):
    def __init__(self, sequence_length=None, num_classes=26, cnn_layers=None,
                 cnn_input_dim=1, rnn_input_dim=256,
                 cnn_hidden_size=256, rnn_hidden_size=512, rnn_num_layers=1, rnn_dropout=0.0,):
        # NOTE: you can freely add hyperparameters argument
        super(ConvLSTM, self).__init__()

        # define the properties, you can freely modify or add hyperparameters
        self.cnn_hidden_size = cnn_hidden_size
        self.rnn_hidden_size = rnn_hidden_size
        self.cnn_input_dim = cnn_input_dim
        self.rnn_input_dim = rnn_input_dim
        self.rnn_num_layers = rnn_num_layers
        self.sequence_length = sequence_length
        self.num_classes = num_classes
        ##############################################################################
        #                          IMPLEMENT YOUR CODE                               #
        ##############################################################################
        self.conv = CustomCNN()
        self.lstm = LSTM(rnn_input_dim,rnn_hidden_size,num_classes,rnn_num_layers,rnn_dropout)
        self.FC = nn.Linear(num_classes,rnn_input_dim).cuda()

        self.init_lstm = torch.nn.LSTM(input_size = rnn_hidden_size, hidden_size = rnn_hidden_size, num_layers= rnn_num_layers, dropout = rnn_dropout)
        # NOTE: you can define additional parameters
        ##############################################################################
        #                          END OF YOUR CODE                                  #
        ##############################################################################

    def forward(self, inputs):
        """
        input is (imgaes, labels) (training phase) or images (test phase)
        images: sequential features of Batch size X (Sequence_length, Channel=1, Height, Width)
        labels: Batch size X (Sequence_length)
        outputs should be a size of Batch size X (1, Num_classes) or Batch size X (Sequence_length, Num_classes)
        """






        # for teacher-forcing
        have_labels = False
        if len(inputs) == 2:
            have_labels = True
            images, labels = inputs
        else:
            images = inputs

        ##############################################################################
        #                          IMPLEMENT YOUR CODE                               #
        ##############################################################################
        # Problem3: input image into CNN and RNN sequentially.
        # NOTE: you can use teacher-forcing using labels or not
        # NOTE: you can modify below hint code 


        batch_size = len(images) #256

        #images? batch size * (seqlen, 1, 28, 28)
        hidden_state = torch.zeros((self.rnn_num_layers, batch_size, self.rnn_hidden_size)).cuda()
        cell_state = torch.zeros((self.rnn_num_layers, batch_size, self.rnn_hidden_size)).cuda()

        seq_lengths = torch.tensor([images[i].shape[0] for i in range(0,len(images))]) #torch.tensor(len1, len2, ...)
        seq_lengths_sorted, perm_idx = seq_lengths.sort(0,descending=True)

        #print(seq_lengths_sorted)

        seq_lengths_acc = torch.zeros(seq_lengths.max(), dtype = torch.int64)

        for i in range(0, batch_size):
          for j in range(0, seq_lengths_sorted[i]):
            seq_lengths_acc[j] += 1

        #print("acc:",seq_lengths_acc)


        hidden_feature = [self.conv(image.cuda()) for image in images]

        hidden_feature_sorted = [hidden_feature[i] for i in perm_idx]

        rnn_input = torch.nn.utils.rnn.pad_sequence(hidden_feature_sorted) # maxlen, batch_Size,  64
        
        _ , hidden_state, cell_state = self.lstm(rnn_input, hidden_state, cell_state) #input : Seq, H=64     
   
        start = torch.zeros(1,batch_size,self.rnn_input_dim).cuda()
        out, hidden_state, cell_state = self.lstm(start,hidden_state,cell_state)     

        
        outputs = []
        outputs.append(out)

        if have_labels:
            # training code ...
            #label : batch_size * (seq_lengths)
          #rnn_input = torch.nn.utils.rnn.pad_sequence(hidden_feature, batch_first = True) #batch_Size, maxlen,  64
          #print(labels)
          labels_sorted = [labels[i] for i in perm_idx]
          labels_sorted = torch.nn.utils.rnn.pad_sequence(labels_sorted) # maxlen+1, batch_Size,  64       
          
          teacher_forcing_ratio = 0 # 0.5
          out = self.FC(out)
          for t in range(0,seq_lengths.max() - 1):
            out, hidden_state, cell_state = self.lstm(out,hidden_state,cell_state)
            outputs.append(out)
            teacher_force = random.random() < teacher_forcing_ratio
            if teacher_force:
                out = labels[t].reshape(-1)            
                out = F.one_hot(out.to(torch.int64),self.num_classes).unsqueeze(0)
                out = out.float()
                out = self.FC(out)
            else:
                out = out.argmax(-1).reshape(-1)            
                out = F.one_hot(out,self.num_classes).unsqueeze(0)
                out = out.float()
                out = self.FC(out)   


        else:
          # evaluation code ...
          out = self.FC(out)
          for t in range(0,seq_lengths.max() - 1):
              out, hidden_state, cell_state = self.lstm(out,hidden_state,cell_state)
              outputs.append(out)
              out = out.argmax(-1).reshape(-1)
              out = F.one_hot(out,self.num_classes).unsqueeze(0)
              out = out.float()
              out = self.FC(out)

        #print(len(outputs)) #max_seqlen
        #print([outputs[i].shape for i in range(0,len(outputs))]) #1, batch_size, 26(num_classes)

        #outputs[0]? 0 of seq 0, 1 of seq 0, ... 

        new_outputs = []
        for i in range(0, batch_size):
          out = []
          for j in range(0, seq_lengths_sorted[i]): # from 0 to nth batch
            out.append(outputs[j][0][i])
          out = torch.stack(out)
          new_outputs.append(out)


        _, perm_idx_reverse = perm_idx.sort(0,descending=False)        
        
        outputs = [new_outputs[i] for i in perm_idx_reverse]

        ##############################################################################
        #                          END OF YOUR CODE                                  #
        ##############################################################################
        
        return outputs
